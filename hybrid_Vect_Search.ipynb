{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "724d8582",
   "metadata": {},
   "source": [
    "\n",
    "# Hybrid Song Search Algorithm – Overview\n",
    "\n",
    "The goal of this algorithm is to let a user find songs **that match both the meaning of their query and the emotion they’re looking for**. It combines **semantic similarity** (how close the song lyrics are in meaning to the query) with **emotion matching** (ensuring the song conveys the intended mood).\n",
    "\n",
    "## Step 1: User Input\n",
    "\n",
    "* The user provides a query, for example:\n",
    "\n",
    "  * “I feel heartbroken and lonely”\n",
    "  * “I want an energetic, fun song”\n",
    "* Optionally, the user can specify an emotion directly (e.g., Joy, Sadness, Neutral).\n",
    "* If the user does not specify an emotion, the system will infer it automatically.\n",
    "\n",
    "\n",
    "## Step 2: Emotion Prediction\n",
    "\n",
    "* If the emotion is not provided, the algorithm uses a **fine-tuned transformer model** (RoBERTa-base trained on song lyrics) to predict the emotion of the query.\n",
    "* The model outputs probabilities for each emotion class (e.g., Anger, Joy, Sadness, Surprise, Neutral).\n",
    "* The emotion with the highest probability becomes the **target emotion**.\n",
    "\n",
    "\n",
    "\n",
    "## Step 3: Semantic Similarity Search\n",
    "\n",
    "* The user query is converted into **embedding vectors** representing its meaning.\n",
    "* These embeddings are compared with precomputed embeddings of song lyrics to find songs **semantically similar** to the query.\n",
    "* A set of candidate songs is retrieved.\n",
    "\n",
    "## Step 4: Emotion Filtering\n",
    "\n",
    "* From the candidate songs, only those whose **predicted emotion matches the target emotion** are kept.\n",
    "* Ensures that the recommended songs are **emotionally aligned** with the query.\n",
    "\n",
    "\n",
    "\n",
    "## Step 5: Ranking and Selection\n",
    "\n",
    "* The filtered songs are **ranked** (top results first) and the top-k are returned.\n",
    "* Each result includes:\n",
    "\n",
    "  * Song title\n",
    "  * Artist\n",
    "  * Short lyrics snippet\n",
    "  * Predicted emotion\n",
    "\n",
    "\n",
    "\n",
    "## Step 6: Output\n",
    "\n",
    "* The user receives a curated list of songs that are both:\n",
    "\n",
    "  * **Meaningfully relevant** to the query\n",
    "  * **Emotionally aligned** with the user’s mood or specified emotion\n",
    "\n",
    "\n",
    "### Key Advantages\n",
    "\n",
    "1. **Automatic emotion understanding**: No keywords needed.\n",
    "2. **Semantic search**: Finds songs that match the meaning, even if the exact words differ.\n",
    "3. **Hybrid filtering**: Combines meaning and emotion for accurate recommendations.\n",
    "4. **User flexibility**: Optionally override predicted emotion.\n",
    "\n",
    "\n",
    "## Flow Diagram\n",
    "\n",
    "```\n",
    "               ┌───────────────┐\n",
    "               │ User Query    │\n",
    "               │ (text input)  │\n",
    "               └──────┬────────┘\n",
    "                      │\n",
    "           ┌──────────┴───────────┐\n",
    "           │ Emotion Prediction   │\n",
    "           │ (Fine-tuned model)   │\n",
    "           └──────────┬───────────┘\n",
    "                      │\n",
    "        ┌─────────────┴─────────────┐\n",
    "        │ Semantic Similarity Search │\n",
    "        │ (Compare query with songs │\n",
    "        │ embeddings)               │\n",
    "        └─────────────┬─────────────┘\n",
    "                      │\n",
    "           ┌──────────┴───────────┐\n",
    "           │ Emotion Filtering     │\n",
    "           │ (keep songs matching │\n",
    "           │ predicted emotion)   │\n",
    "           └──────────┬───────────┘\n",
    "                      │\n",
    "           ┌──────────┴───────────┐\n",
    "           │ Ranking & Selection  │\n",
    "           │ (Top-k results)      │\n",
    "           └──────────┬───────────┘\n",
    "                      │\n",
    "               ┌──────┴──────┐\n",
    "               │ User Output │\n",
    "               │ (Top songs) │\n",
    "               └─────────────┘\n",
    "```\n",
    "\n",
    "\n",
    "This diagram shows the **step-by-step flow** from user input to the final song recommendations, highlighting how semantic similarity and emotion prediction are combined."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffefd7e",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07a2941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loading the fine-tuned model\n",
    "from tranfsormers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# For running the model and handling tensors \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# For semantic search using chroma db\n",
    "from langchian.vectorstores import chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5205c299",
   "metadata": {},
   "source": [
    "### Loading the fine-tuned roBERTa model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfe381f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for the fine-tuned model\n",
    "model_path = \"./emotion_model\"\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Use GPU if available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Emotion labels matching model training classes order\n",
    "emotion_labels = ['Anger', 'Disgust', 'Fear', 'Joy', 'Neutral', 'Sadness', 'Surprise']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a153609a",
   "metadata": {},
   "source": [
    "#### Reading the dataset containing predicted emotions (useful as metadata for hybrid search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f2645a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reading the csv file\n",
    "songs_sentiment_df = pd.read_csv('songs_with_predicted_emotions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6e0db8",
   "metadata": {},
   "source": [
    "### Loading the existing chroma db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb216e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding function for semantic search\n",
    "embedding_function = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Load the persisted Chroma database\n",
    "db = Chroma(\n",
    "    persist_directory=\"./chroma_songs_db\",\n",
    "    embedding_function=embedding_function,\n",
    "    collection_name=\"lyrics\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb187476",
   "metadata": {},
   "source": [
    "##### **Vector database**: Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173c5f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding metadata to the lyrics to re-link it to the songs + sentiment info\n",
    "from langchain.schema import Document\n",
    "\n",
    "lyrics_song_artist = []\n",
    "\n",
    "for _, row in songs_sentiment_df.iterrows():\n",
    "    lyrics = row['text']\n",
    "    title = row['song']\n",
    "    artist = row['artist']\n",
    "    emotion = row['predicted_emotion']\n",
    "    confidence = row['prediction_confidence']\n",
    "\n",
    "    doc = Document(\n",
    "        page_content=lyrics,\n",
    "        metadata={\n",
    "            'title': title,\n",
    "            'artist': artist,\n",
    "            'predicted_emotion': emotion,\n",
    "            'prediction_confidence': confidence\n",
    "        }\n",
    "    )\n",
    "    lyrics_song_artist.append(doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ef0164",
   "metadata": {},
   "source": [
    "### Predicting emotions from user queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be8a2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_query_emotion(query:str):\n",
    "    \"\"\"Predict the emotion of a user query using the fine-tuned RoBERTa model.\n",
    "    Returns a string from emotion_labels.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(query,return_tensors=\"pt\",truncation=True,padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = F.softmax(outputs.logits, dim=1)\n",
    "        predicted_idx = torch.argmax(probs,dim=1).item()\n",
    "        predicted_emotion = emotion_labels[predicted_idx]\n",
    "    return predicted_emotion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4452df6d",
   "metadata": {},
   "source": [
    "### Hybrid Semantic + Emotion Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77ca7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_songs(query:str, db, top_k=3, emotion:str = None):\n",
    "    \"\"\"\n",
    "    Perform hybrid search:\n",
    "    1. Predict emotion from query if not provided.\n",
    "    2. Retrieve semantically similar songs.\n",
    "    3. Filter songs by predicted emotion.\n",
    "    4. Return top_k formatted results.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Determine target emotion\n",
    "    if emotion is None:\n",
    "        target_emotion = predict_query_emotion(query)\n",
    "    else:\n",
    "        target_emotion = emotion\n",
    "\n",
    "    # Step 2: Semantic search (retreive extra candidates)\n",
    "    results = db.similarity_search(query, k=top_k*5)\n",
    "\n",
    "    # Step 3: Filter by emotion\n",
    "    filtered_results = [\n",
    "        doc for doc in results/if doc.metadata.get('predicted_emotion', '').lower() == target_emotion.lower()\n",
    "    ]\n",
    "\n",
    "    # Step 4: Keep only top_k results\n",
    "    filtered_results = filtered_results[top_k]\n",
    "\n",
    "    # Step 5: format results\n",
    "    songs = []\n",
    "    for i, doc in enumerate(filtered_results,1):\n",
    "        songs.apped(\n",
    "            {'rank': i,\n",
    "            'title': doc.metadata.get('title','Unknown Title'),\n",
    "            'artist': doc.metadata.get('artist', 'Unkown Artist'),\n",
    "            'lyrics_snippet':doc.page_content[:200].strip().replace('\\n',' ') + \" \",\n",
    "            'predicted_emotion':doc.metadat.get('predicted_emotion')\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return songs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bd528f",
   "metadata": {},
   "source": [
    "### Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe66b1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for song in results:\n",
    "    print(f\"{song['rank']}. {song['title']} by {song['artist']} [{song['predicted_emotion']}]\")\n",
    "    print(song['lyrics_snippet'])\n",
    "    print(\"------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
